{"worksheets":[{"cells":[{"prompt_number":null,"outputs":[{"text":""}],"id":"2db8d8b0-a289-4ac8-b9e9-22d9cda5f8d7","content":["# Nx - Numerical Elixir\r\n![](https://github.com/elixir-nx/nx/raw/main/nx/nx.png)\r\n\r\nhttps://github.com/elixir-nx/nx\r\n\r\nJosÃ© Valim teased us for months about Nx without telling us what it was but now that wait is over and it's finally out!! "],"cell_type":"markdown"},{"prompt_number":null,"outputs":[{"text":""}],"id":"760c3e9f-f5c0-4793-8711-d3e487f97827","content":["# Nx - Numerical Elixir\r\n\r\n_Nx is a multi-dimensional tensors library for Elixir with multi-staged compilation to the CPU/GPU._\r\n\r\nIt aims to address the issue that the BEAM platform performs poorly in compute-intensive domains such as Machine Learning, Numerical Analysis, etc.\r\n\r\nNx includes (https://github.com/elixir-nx/nx/blob/main/nx/README.md):\r\n - typed multi-dimensional tensors (multi-dimensional arrays)\r\n - functions to create, manipulate, and perform operations on tensors\r\n - automatic differentiation (autograd), useful for model training\r\n - backends - work with tensors stored in memory (binary), on the GPU, etc\r\n - numerical definitions - `defn`\r\n   - use a large subset of Elixir syntax to AOT or JIT compile tensor code to CPU or GPU\r\n\r\nAs an API, Nx draws inspiration from Python's `NumPy` and `JAX` libraries.\r\nIt intends to be an Elixir-based alternative to the likes of TensorFlow or PyTorch.\r\n\r\nWith the introduction of Nx, Elixir now can now stake a claim in another domain, allowing us to solve more problems with the one platform!\r\n\r\n"],"cell_type":"markdown"},{"prompt_number":null,"outputs":[{"text":""}],"id":"00c621ce-0a1f-4f7f-a964-9d106e950dd8","content":["## Agenda\r\n - meta\r\n - tensors\r\n - Nx API\r\n - numerical definitions\r\n - backends"],"cell_type":"markdown"},{"prompt_number":null,"outputs":[{"text":""}],"id":"7ea0c8ea-32aa-4415-833f-14137002650d","content":["## Meta\r\n\r\n### Code notebook \r\n\r\nThis environment is an Niex notebook - an interactive Elixir code notebook.\r\n\r\nhttps://github.com/jonklein/niex\r\n\r\nThis particular notebook can be found here.\r\n\r\nEach code block needs to be run in turn, and if an upstream block is changed, then all blocks below that depend upon it will have stale data and must also be re-run.\r\n\r\n### Mathematics disclaimer\r\n\r\nThe author is a beginner in the world of tensors and numerical computing.  Take any mathematical or scientific claim with a grain of salt."],"cell_type":"markdown"},{"prompt_number":null,"outputs":[{"text":""}],"id":"0da4b928-2e2a-4f50-a2ff-12c81ad5d32e","content":["## Tensors\r\n\r\n> _a __tensor__ is an algebraic object that describes a (multilinear) relationship between sets of algebraic objects related to a vector space_\r\n\r\nhttps://en.wikipedia.org/wiki/Tensor"],"cell_type":"markdown"},{"prompt_number":null,"outputs":[{"text":""}],"id":"962ab8f2-2aed-468f-8f31-195b0dc2f515","content":["## Tensors -- take two\r\n\r\nTensors are algebraic objects that may be represented as an array with 0 or more dimensions.\r\nFor instance, a 0-dimension array can represent a scalar value, 1-dimensional array can represent a vector, and so on.\r\n\r\nThe number of dimensions of the array are referred to as the tensor _rank_.  Rank tells you how many indicies are needed to identify a scalar component (element) of the tensor.  For example, we could use the indicies `i` and `j` to identify components in a rank-2 tensor, just like we would use them in a nested loop to iterate through a nested array.\r\n\r\nRelating tensors to other algebraic objects, a rank-0 tensor is a scalar, a rank-1 tensor is a vector, and a rank-2 tensor _can be represented_ as a matrix.\r\n\r\nThe length of each dimension of the array is the tensor _dimension_.\r\n\r\n--> Under the strict mathematical definition, the lengths of each dimension of the array should all be the same, e.g. a rank-2 tensor of dimension 3 could be represented as a 3x3 array (which is also a 3x3 matrix).  The `i` and `j` indicies above would have values ranging from 0 to 2.\r\n\r\nMathematically, tensors also have some other defining properties, whereby, for example, a tensor describing some physical system has the same meaning regardless of the frame of reference."],"cell_type":"markdown"},{"prompt_number":null,"outputs":[{"text":""}],"id":"257682e4-81c4-4ea4-8762-cc4524b24af1","content":["## Tensors -- Nx-style\r\n\r\nIn Nx, tensors are a data structure that embellishes a multi-dimensional array (__not__ a list) with extra properties, such as a shape, labelled dimensions, and an element type"],"cell_type":"markdown"},{"prompt_number":null,"outputs":[{"text":""}],"id":"e3ce2fd3-c860-4c38-b43d-17abe0b19230","content":["## Tensor creation\r\nhttps://seanmoriarity.com/2021/03/04/nx-tip-of-the-week-3-many-ways-to-create-arrays/"],"cell_type":"markdown"},{"prompt_number":null,"outputs":[{"text":""}],"id":"33c730bb-49c9-433e-8365-fb38985170f5","content":["We can construct a tensor out of a multi-dimensional list"],"cell_type":"markdown"},{"running":false,"prompt_number":0,"outputs":[{"type":"code","text":["#Nx.Tensor<\n  s64[3][3]\n  [\n    [1, 2, 3],\n    [4, 5, 6],\n    [7, 8, 9]\n  ]\n>"]}],"id":"6c4dbb50-19ce-41b3-aa93-6ede67c1cefc","content":["t1 = Nx.tensor([[1,2,3], [4,5,6]])"],"cell_type":"code"},{"running":false,"prompt_number":1,"outputs":[{"type":"code","text":["#Nx.Tensor<\n  f32[x: 3][y: 2]\n  [\n    [1.5, 2.5],\n    [1.0, 3.0],\n    [4.0, 6.0]\n  ]\n>"]}],"id":"de09b483-ea8f-482a-a3d5-449ede5624cd","content":["t2 = Nx.tensor([[1.5, 2.5], [1, 3], [4, 6]], names: [:x, :y])"],"cell_type":"code"},{"prompt_number":null,"outputs":[{"text":""}],"id":"6f2b0b4a-ba9e-42ae-b5b1-7bf8f4425127","content":["The type of each element is inferred or it can be specified"],"cell_type":"markdown"},{"running":false,"prompt_number":2,"outputs":[{"type":"code","text":["#Nx.Tensor<\n  f64[2][2]\n  [\n    [1.5, 2.5],\n    [1.0, 3.0]\n  ]\n>"]}],"id":"dd43fb56-a171-4b77-9fed-acb08cb5af84","content":["t_f64 = Nx.tensor([[1.5, 2.5], [1, 3]], type: {:f, 64})"],"cell_type":"code"},{"prompt_number":null,"outputs":[{"text":""}],"id":"ffba580d-684c-48a1-b038-d40f52b080e4","content":["We can ask a tensor about its properties"],"cell_type":"markdown"},{"running":false,"prompt_number":3,"outputs":[{"type":"code","text":["\"t2 has shape {3, 2}, type {:f, 32}, and dimension names [:x, :y]\""]}],"id":"7190e1cd-665b-4e93-a5ad-bfd2bfd68140","content":["\"t2 has shape #{inspect Nx.shape(t2)}, type #{inspect Nx.type(t2)}, and dimension names #{inspect Nx.names(t2)}\""],"cell_type":"code"},{"prompt_number":null,"outputs":[{"text":""}],"id":"9ea83bdc-5ff1-4d17-80dc-ce06d917df18","content":["Tensors can also be created out of binaries.  This is more efficient than creating from a list as tensors are usually stored as binaries natively, and lists must be fully traversed to build up the binary equivalent."],"cell_type":"markdown"},{"running":false,"prompt_number":4,"outputs":[{"type":"code","text":["#Nx.Tensor<\n  s64[8]\n  [0, 2, 4, 8, 16, 32, 64, 128]\n>"]}],"id":"13500ed5-e65d-46cf-bf3d-449b000cfc75","content":["t3 = Nx.from_binary(<<0::64-signed-native, 2::64-signed-native, 4::64-signed-native, 8::64-signed-native, 16::64-signed-native, 32::64-signed-native, 64::64-signed-native, 128::64-signed-native>>, {:s, 64})"],"cell_type":"code"},{"prompt_number":null,"outputs":[{"text":""}],"id":"e02294b4-83f4-445c-89fc-8d451ad15ef5","content":["`Nx.from_binary/2` creates a flat list from the binary data.  We can reshape the tensor if the data actually represents multi-dimensional data.  This operation does not actually modify the underlying binary, it merely reshapes the input tensor."],"cell_type":"markdown"},{"running":false,"prompt_number":5,"outputs":[{"type":"code","text":["#Nx.Tensor<\n  s64[2][4]\n  [\n    [0, 2, 4, 8],\n    [16, 32, 64, 128]\n  ]\n>"]}],"id":"451f658d-96ad-479b-9003-bc141b2fef51","content":["t3 |> Nx.reshape({2,4})"],"cell_type":"code"},{"prompt_number":null,"outputs":[{"text":""}],"id":"45423490-7a8e-4a42-9c3b-9e66e710e9ca","content":["We can create tensors from shapes and other tensors with `Nx.broadcast/3`"],"cell_type":"markdown"},{"running":false,"prompt_number":6,"outputs":[{"type":"code","text":["#Nx.Tensor<\n  s64[3][2]\n  [\n    [1, 1],\n    [1, 1],\n    [1, 1]\n  ]\n>"]}],"id":"32c28cba-f1f8-49a1-9d68-6fb285d60f1d","content":["Nx.broadcast(1, {3, 2})"],"cell_type":"code"},{"running":false,"prompt_number":7,"outputs":[{"type":"code","text":["#Nx.Tensor<\n  s64[4][3]\n  [\n    [1, 2, 3],\n    [1, 2, 3],\n    [1, 2, 3],\n    [1, 2, 3]\n  ]\n>"]}],"id":"3735f5e6-9e27-4f47-9372-9c921556eaef","content":["Nx.broadcast(Nx.tensor([1,2,3]), {4, 3})"],"cell_type":"code"},{"prompt_number":null,"outputs":[{"text":""}],"id":"56a76bcd-9ab3-4d2a-84a3-a1b2e1ed5578","content":["`Nx.iota/2` can be used to create a tensor with increasing values"],"cell_type":"markdown"},{"running":false,"prompt_number":8,"outputs":[{"type":"code","text":["#Nx.Tensor<\n  s64[4][4]\n  [\n    [0, 1, 2, 3],\n    [4, 5, 6, 7],\n    [8, 9, 10, 11],\n    [12, 13, 14, 15]\n  ]\n>"]}],"id":"560f17bb-1f71-410a-a26f-58dd36aeab51","content":["Nx.iota({4,4})"],"cell_type":"code"},{"running":false,"prompt_number":9,"outputs":[{"type":"code","text":["#Nx.Tensor<\n  s64[4][4]\n  [\n    [0, 0, 0, 0],\n    [1, 1, 1, 1],\n    [2, 2, 2, 2],\n    [3, 3, 3, 3]\n  ]\n>"]}],"id":"2a2b6459-d801-4d94-ae8f-5a81905f4492","content":["Nx.iota({4,4}, axis: 0)"],"cell_type":"code"},{"prompt_number":null,"outputs":[{"text":""}],"id":"1fee28d6-3d37-4864-b451-9a6d9c3ad448","content":["Operations, which we will look at next, can be used with `Nx.iota/2` to create interesting tensors"],"cell_type":"markdown"},{"running":false,"prompt_number":10,"outputs":[{"type":"code","text":["#Nx.Tensor<\n  u8[3][3]\n  [\n    [1, 0, 0],\n    [0, 1, 0],\n    [0, 0, 1]\n  ]\n>"]}],"id":"e37786c6-63e2-4446-b355-06f25b42d838","content":["a = Nx.iota({3, 3}, axis: 0)\r\nb = Nx.iota({3, 3}, axis: 1)\r\nNx.equal(a, b)"],"cell_type":"code"},{"prompt_number":null,"outputs":[{"text":""}],"id":"d246c495-9826-4b49-bef3-01c71a9401c6","content":["## Tensor operations\r\n\r\nNx, being tensor/array based, may lead us to guess that we can use `Enum`, or something like it, to manipulate tensors.\r\n\r\nIndeed, Nx does provide `Nx.map/3` and `Nx.reduce/3`.  However, use of these functions is discouraged as they can lead to verbose and inefficient code.\r\n\r\nFortunately, Nx provides many _tensor-aware_ functions for element-wise and aggregate operations.\r\n\r\nhttps://seanmoriarity.com/2021/02/24/nx-tip-of-the-week-2-tensor-manipulation-for-elixir-programmers/\r\n"],"cell_type":"markdown"},{"prompt_number":null,"outputs":[{"text":""}],"id":"a89d8758-883b-40da-a122-e2fc538642d4","content":["Element-wise unary ops\r\n\r\n```\r\n:exp, :expm1, :log, :log1p, :logistic, :cos, :sin, :tanh, :sqrt, :rsqrt, :cbrt,\r\n:acosh, :asinh, :atanh, :acos, :asin, :atan, :cosh, :sinh,\r\n:erf, :erfc, :erf_inv\r\n:negate\r\n:count_leading_zeros, :population_count, :bitwise_not\r\n:abs, :sign\r\n:floor, :ceil, :round\r\n```"],"cell_type":"markdown"},{"running":false,"prompt_number":11,"outputs":[{"type":"code","text":["#Nx.Tensor<\n  f32[3]\n  [2.7182817459106445, 7.389056205749512, 20.08553695678711]\n>"]}],"id":"e2faf110-49f7-4049-9444-6cba1e8560e8","content":["Nx.tensor([1,2,3]) |> Nx.exp"],"cell_type":"code"},{"running":false,"prompt_number":12,"outputs":[{"type":"code","text":["#Nx.Tensor<\n  f32[1][100]\n  [\n    [0.0, 0.2742193043231964, 0.52741539478302, 0.7401768565177917, 0.8961922526359558, 0.9835004210472107, 0.9954079389572144, 0.9310019016265869, 0.7952200174331665, 0.5984721183776855, 0.35584187507629395, 0.0859309658408165, -0.19056811928749084, -0.4524569511413574, -0.6796581149101257, -0.854752779006958, -0.9643172025680542, -0.9999516606330872, -0.9589242935180664, -0.8443801403045654, -0.6651012897491455, -0.4348320960998535, -0.17122623324394226, 0.10550680011510849, 0.3741515278816223, 0.6141112446784973, 0.8069897890090942, 0.937999963760376, 0.997097909450531, 0.9797527194023132, 0.887293815612793, 0.7268102169036865, 0.5106053352355957, 0.2552545666694641, -0.01966542750597, -0.2930777668952942, -0.5440211296081543, -0.7532567977905273, -0.904744029045105, -0.9868679046630859, -0.9933329820632935, -0.9236436486244202, -0.783142626285553, -0.5826016068458557, -0.337395042181015, -0.06632189452648163, 0.20983584225177765, 0.4699072241783142, 0.6939519643783569, 0.8647945523262024, ...]\n  ]\n>"]}],"id":"129bb065-52e3-40a7-a011-be748644f33e","content":["t_sin_x = Nx.iota({1,100}) |> Nx.divide(3.6)\r\nt_sin_y = t_sin_x |> Nx.sin"],"cell_type":"code"},{"running":false,"prompt_number":13,"outputs":[{"type":"html","text":"<div class=\"chart\" style=\"width: 480px; height: 360px\" phx-hook=\"NiexChart\" data-chart='{\"type\":\"LineChart\",\"options\":{\"width\":480,\"points\":false,\"height\":360},\"data\":[[0.0,0.0],[0.2777777910232544,0.2742193043231964],[0.5555555820465088,0.52741539478302],[0.8333333730697632,0.7401768565177917],[1.1111111640930176,0.8961922526359558],[1.388888955116272,0.9835004210472107],[1.6666667461395264,0.9954079389572144],[1.9444445371627808,0.9310019016265869],[2.222222328186035,0.7952200174331665],[2.5,0.5984721183776855],[2.777777910232544,0.35584187507629395],[3.055555582046509,0.0859309658408165],[3.3333334922790527,-0.19056811928749084],[3.6111111640930176,-0.4524569511413574],[3.8888890743255615,-0.6796581149101257],[4.1666669845581055,-0.854752779006958],[4.44444465637207,-0.9643172025680542],[4.722222328186035,-0.9999516606330872],[5.0,-0.9589242935180664],[5.277778148651123,-0.8443801403045654],[5.555555820465088,-0.6651012897491455],[5.833333492279053,-0.4348320960998535],[6.111111164093018,-0.17122623324394226],[6.388888835906982,0.10550680011510849],[6.6666669845581055,0.3741515278816223],[6.94444465637207,0.6141112446784973],[7.222222328186035,0.8069897890090942],[7.5,0.937999963760376],[7.777778148651123,0.997097909450531],[8.05555534362793,0.9797527194023132],[8.333333969116211,0.887293815612793],[8.611111640930176,0.7268102169036865],[8.88888931274414,0.5106053352355957],[9.166666984558105,0.2552545666694641],[9.44444465637207,-0.01966542750597],[9.722222328186035,-0.2930777668952942],[10.0,-0.5440211296081543],[10.277777671813965,-0.7532567977905273],[10.555556297302246,-0.904744029045105],[10.833333969116211,-0.9868679046630859],[11.111111640930176,-0.9933329820632935],[11.38888931274414,-0.9236436486244202],[11.666666984558105,-0.783142626285553],[11.94444465637207,-0.5826016068458557],[12.222222328186035,-0.337395042181015],[12.5,-0.06632189452648163],[12.777777671813965,0.20983584225177765],[13.055556297302246,0.4699072241783142],[13.333333969116211,0.6939519643783569],[13.611111640930176,0.8647945523262024],[13.88888931274414,0.9693371057510376],[14.166666984558105,0.9995648860931396],[14.44444465637207,0.9531605243682861],[14.722222328186035,0.8336815237998962],[15.0,0.6502878665924072],[15.277778625488281,0.41703861951828003],[15.555556297302246,0.15181763470172882],[15.833333969116211,-0.12504252791404724],[16.11111068725586,-0.3923153877258301],[16.38888931274414,-0.6295128464698792],[16.666667938232422,-0.818448007106781],[16.94444465637207,-0.9446353316307068],[17.22222328186035,-0.9984022378921509],[17.5,-0.9756259918212891],[17.77777862548828,-0.8780524134635925],[18.05555534362793,-0.7131633758544922],[18.33333396911621,-0.49359792470932007],[18.61111068725586,-0.23619213700294495],[18.88888931274414,0.03932324796915054],[19.166667938232422,0.31182387471199036],[19.44444465637207,0.560416579246521],[19.72222328186035,0.7660462260246277],[20.0,0.9129452705383301],[20.27777862548828,0.98985356092453],[20.55555534362793,0.9908739924430847],[20.83333396911621,0.9159281849861145],[21.111112594604492,0.7707617878913879],[21.38888931274414,0.5665056705474854],[21.666667938232422,0.31881657242774963],[21.94444465637207,0.046686939895153046],[22.22222328186035,-0.2290237993001938],[22.5,-0.48717451095581055],[22.77777862548828,-0.707977294921875],[23.05555534362793,-0.8745013475418091],[23.33333396911621,-0.9739821553230286],[23.611112594604492,-0.998791515827179],[23.88888931274414,-0.9470280408859253],[24.166667938232422,-0.8226596117019653],[24.44444465637207,-0.6352224946022034],[24.72222328186035,-0.39908429980278015],[25.0,-0.13235175609588623],[25.27777862548828,0.14452943205833435],[25.55555534362793,0.41032835841178894],[25.83333396911621,0.6446709036827087],[26.111112594604492,0.8295890688896179],[26.38888931274414,0.9509053230285645],[26.666667938232422,0.999320387840271],[26.94444465637207,0.9711219668388367],[27.22222328186035,0.8684714436531067],[27.5,0.6992400288581848]]}' id=\"d55387e3-92a0-40a8-98c5-1442fbc1552a}\" />\n"}],"id":"53b172e6-39c9-496d-a248-2fc20ee09ad3","content":["x = t_sin_x |> Nx.to_flat_list()\r\ny = t_sin_y |> Nx.to_flat_list()\r\nsine_wave = Enum.zip(x, y) |> Enum.map(fn {x,y} -> [x, y] end)\r\nNiex.Content.chart(\"LineChart\", sine_wave, points: false)"],"cell_type":"code"},{"prompt_number":null,"outputs":[{"text":""}],"id":"f2bb6324-7a34-4927-9374-b09f4a6ddf2e","content":["Element-wise binary ops\r\n\r\n```\r\n:add, :subtract, :multiply, :divide, :max, :min, :remainder, :atan2, :power,\r\n:bitwise_and, :bitwise_or, :bitwise_xor,\r\n:left_shift, :right_shift_arithmetic, :right_shift_logical,\r\n:equal, :not_equal, :greater, :less, :greater_equal, :less_equal,\r\n```"],"cell_type":"markdown"},{"running":false,"prompt_number":14,"outputs":[{"type":"code","text":["#Nx.Tensor<\n  s64[2][3]\n  [\n    [2, 4, 6],\n    [8, 10, 12]\n  ]\n>"]}],"id":"5b8a4be7-31eb-4b0c-b3da-bfe974377ed8","content":["a = Nx.tensor([[1,2,3], [4,5,6]])\r\nb = Nx.tensor([[1,2,3], [4,5,6]])\r\nNx.add(a,b)"],"cell_type":"code"},{"prompt_number":null,"outputs":[{"text":""}],"id":"ca80ed3b-da74-4c35-97af-4802ccc58f0b","content":["Aggregate ops\r\n\r\n```\r\nconv, all?, any?, sum, product, reduce_max, reduce_min, argmax, argmin, reduce, \r\nreduce_window, window_sum, window_product, window_max, window_min, map, sort,\r\nscatter_window_max, scatter_window_min\r\n```"],"cell_type":"markdown"},{"running":false,"prompt_number":15,"outputs":[{"type":"code","text":["#Nx.Tensor<\n  s64\n  21\n>"]}],"id":"fc2cb1e9-c37f-487e-a99a-6efac831fb2e","content":["Nx.tensor([[1,2,3], [4,5,6]]) |> Nx.sum"],"cell_type":"code"},{"running":false,"prompt_number":16,"outputs":[{"type":"code","text":["#Nx.Tensor<\n  s64[3]\n  [5, 7, 9]\n>"]}],"id":"e62421d6-a7cc-43c5-b85a-a27b966b27d4","content":["Nx.tensor([[1,2,3], [4,5,6]]) |> Nx.sum(axes: [0])"],"cell_type":"code"},{"running":false,"prompt_number":17,"outputs":[{"type":"code","text":["#Nx.Tensor<\n  s64[2]\n  [6, 15]\n>"]}],"id":"a49bdbf6-81d3-4615-8c64-18e1d463d2ac","content":["Nx.tensor([[1,2,3], [4,5,6]]) |> Nx.sum(axes: [1])"],"cell_type":"code"},{"prompt_number":null,"outputs":[{"text":""}],"id":"ab91ee25-b922-4d5c-b949-98d819e1453c","content":["Other\r\n\r\n```\r\ndot, clip, slice, concatenate, select\r\n```"],"cell_type":"markdown"},{"running":false,"prompt_number":18,"outputs":[{"type":"code","text":["#Nx.Tensor<\n  s64[2][2]\n  [\n    [5, 11],\n    [11, 25]\n  ]\n>"]}],"id":"ff6c2290-4918-478b-879b-da7fd7fd85c1","content":["tt = Nx.tensor([[1,2],[3,4]])\r\nNx.dot(tt, [1], tt, [1])"],"cell_type":"code"},{"running":false,"prompt_number":19,"outputs":[{"type":"code","text":["#Nx.Tensor<\n  s64[2][2]\n  [\n    [5, 6],\n    [7, 8]\n  ]\n>"]}],"id":"e40e771b-9083-4650-b664-bba13b71e1f3","content":["ta = Nx.tensor([[1,6],[3,8]])\r\ntb = Nx.tensor([[5,2],[7,4]])\r\ncmp = Nx.greater_equal(ta,tb)\r\nNx.select(cmp,ta,tb)"],"cell_type":"code"},{"prompt_number":null,"outputs":[{"text":""}],"id":"3fb52d38-0ecf-4df1-877e-3eca6af3ba0d","content":["## BEAM numerical computation performance\r\n\r\n\r\n - Q: Why don't people use Erlang to forecast the weather?\r\n - A (Robert Virding): Because you would get tomorrow's forecast next week\r\n\r\nWhile the BEAM has fantastic concurrency and IO throughput, its interpreted nature (even with upcoming JIT compilation), dynamic type system, and lack of SIMD instructions limits raw computational performance."],"cell_type":"markdown"},{"prompt_number":null,"outputs":[{"text":""}],"id":"f59f486c-3094-4673-bdb4-e481dea01399","content":["## `defn` - Numerical Definitions\r\nNx introduces `defn` (Numerical Definitions) - a construct to develop numerical code in a large subset of the Elixir language\r\n - Numerical definitions provide a set of infix operators that delegate to the tensor-aware `Nx.*` functions\r\n - Nx introduces `Nx.Defn.Kernel` which replaces `Kernel` inside `defn`s\r\n\r\n"],"cell_type":"markdown"},{"running":false,"prompt_number":20,"outputs":[{"type":"code","text":["{:module, Formula, <<70, 79, 82, 49, 0, 0, 13, 252, 66, 69, 65, 77, 65, 116, 85, 56, 0, 0, 1, 248, 0, 0, 0, 41, 14, 69, 108, 105, 120, 105, 114, 46, 70, 111, 114, 109, 117, 108, 97, 8, 95, 95, 105, 110, 102, 111, 95, ...>>, {:portion, 1}}"]}],"id":"dc132249-3b1a-4a16-a2aa-df398f0db5e5","content":["defmodule Formula do\r\n  import Nx.Defn  // so we can use defn\r\n\r\n  defn softmax(t) do\r\n    Nx.exp(t) / Nx.sum(Nx.exp(t))\r\n  end\r\n  \r\n  defn portion(t) do\r\n    t / Nx.sum(t)\r\n  end\r\nend"],"cell_type":"code"},{"running":false,"prompt_number":21,"outputs":[{"type":"code","text":["#Nx.Tensor<\n  f32[4]\n  [0.032058604061603546, 0.08714432269334793, 0.23688282072544098, 0.6439142227172852]\n>"]}],"id":"9b529c15-e49e-4b0e-b16c-a0b3b2ab50fe","content":["[1, 2, 3, 4] |> Nx.tensor |> Formula.softmax"],"cell_type":"code"},{"running":false,"prompt_number":22,"outputs":[{"type":"code","text":["#Nx.Tensor<\n  f32[4]\n  [0.10000000149011612, 0.20000000298023224, 0.30000001192092896, 0.4000000059604645]\n>"]}],"id":"0de0e948-b5bf-43a8-8d22-bec46b06a0fa","content":["[1, 2, 3, 4] |> Nx.tensor |> Formula.portion"],"cell_type":"code"},{"running":false,"prompt_number":23,"outputs":[{"type":"html","text":"<div class=\"chart\" style=\"width: 480px; height: 360px\" phx-hook=\"NiexChart\" data-chart='{\"type\":\"ScatterChart\",\"options\":{\"width\":480,\"height\":360},\"data\":{\"0.1818181872367859\":0.6321492195129395,\"0.16363635659217834\":0.23255471885204315,\"0.145454540848732\":0.08555210381746292,\"0.12727272510528564\":0.03147285804152489,\"0.1090909093618393\":0.011578218080103397,\"0.09090909361839294\":0.00425938842818141,\"0.072727270424366\":0.001566941267810762,\"0.05454545468091965\":5.764455418102443e-4,\"0.036363635212183\":2.1206245583016425e-4,\"0.0181818176060915\":7.801341416779906e-5}}' id=\"88d80c12-7ea2-45fd-b0a7-3fde082e8baa}\" />\n"}],"id":"6eb950fa-b0bf-4d61-9075-8619f8f9fa70","content":["t1 = 1..10 |> Enum.to_list |> Nx.tensor()\r\nsm = t1 |> Formula.softmax |> Nx.to_flat_list()\r\np = t1 |> Formula.portion |> Nx.to_flat_list()\r\ndata1 = Enum.zip(p, sm) |> Enum.into(%{})\r\nNiex.Content.chart(\"ScatterChart\", data1)\r\n"],"cell_type":"code"},{"prompt_number":null,"outputs":[{"text":""}],"id":"3bc0300b-b9c7-452d-8824-c6a8e3a11350","content":["### `defn` produces a computation graph of the tensor operations"],"cell_type":"markdown"},{"running":false,"prompt_number":24,"outputs":[{"type":"code","text":["{:module, Formula, <<70, 79, 82, 49, 0, 0, 25, 16, 66, 69, 65, 77, 65, 116, 85, 56, 0, 0, 3, 99, 0, 0, 0, 59, 14, 69, 108, 105, 120, 105, 114, 46, 70, 111, 114, 109, 117, 108, 97, 8, 95, 95, 105, 110, 102, 111, 95, ...>>, {:graph_grad_softmax, 1}}"]}],"id":"567abb87-6118-4aac-a97d-51879e493ef3","content":["defmodule Formula do\r\n  import Nx.Defn\r\n\r\n  def raise(x) do\r\n    x |> inspect |> Kernel.raise\r\n  end\r\n\r\n  defmacro graph (expr) do\r\n    quote do\r\n      Nx.Defn.Kernel.transform(\r\n        unquote(expr),\r\n        &Formula.raise/1\r\n      )\r\n    end\r\n  end\r\n\r\n  defn softmax(t) do\r\n    Nx.exp(t) / Nx.sum(Nx.exp(t))\r\n  end\r\n\r\n  defn grad_softmax(t) do\r\n    grad(t, Nx.exp(t) / Nx.sum(Nx.exp(t)))\r\n  end\r\n\r\n  defn graph_softmax(t) do\r\n    t |> softmax |> graph\r\n  end\r\n\r\n  defn graph_grad_softmax(t) do\r\n    t |> grad_softmax |> graph\r\n  end\r\n \r\nend"],"cell_type":"code"},{"running":false,"prompt_number":25,"outputs":[{"type":"html","text":"<pre>** (RuntimeError) #Nx.Tensor<\n  f32[4]\n  \n  Nx.Defn.Expr\n  parameter a                                 s64[4]\n  b = exp [ a ]                               f32[4]\n  c = exp [ a ]                               f32[4]\n  d = sum [ c, axes: nil, keep_axes: false ]  f32\n  e = divide [ b, d ]                         f32[4]\n>    nofile:5: Formula.raise/1\n    nofile:25: anonymous fn/1 in Formula.graph_softmax/1\n    (nx 0.1.0-dev) lib/nx/defn/evaluator.ex:20: Nx.Defn.Evaluator.__jit__/4\n    (stdlib 3.14) erl_eval.erl:680: :erl_eval.do_apply/6\n    (stdlib 3.14) erl_eval.erl:232: :erl_eval.expr/5\n    (stdlib 3.14) erl_eval.erl:888: :erl_eval.expr_list/6\n    (stdlib 3.14) erl_eval.erl:411: :erl_eval.expr/5\n    (elixir 1.11.3) src/elixir.erl:280: :elixir.recur_eval/3\n    (elixir 1.11.3) src/elixir.erl:265: :elixir.eval_forms/3\n    (elixir 1.11.3) lib/code.ex:700: Code.eval_quoted/3\n</pre>\n"}],"id":"e8d8d51d-f86a-480b-a9c0-5f37243f9460","content":["import Formula\r\n[1, 2, 3, 4] |> Nx.tensor |> Formula.graph_softmax"],"cell_type":"code"},{"running":false,"prompt_number":26,"outputs":[{"type":"html","text":"<pre>** (RuntimeError) #Nx.Tensor<\n  f32\n  \n  Nx.Defn.Expr\n  parameter a                                 s64\n  b = exp [ a ]                               f32\n  c = sum [ b, axes: nil, keep_axes: false ]  f32\n  d = divide [ 1.0, c ]                       f32\n  e = exp [ a ]                               f32\n  f = multiply [ d, e ]                       f32\n  g = divide [ e, c ]                         f32\n  h = multiply [ 1.0, g ]                     f32\n  i = divide [ h, c ]                         f32\n  j = multiply [ i, b ]                       f32\n  k = subtract [ f, j ]                       f32\n>    nofile:5: Formula1.raise/1\n    nofile:29: anonymous fn/1 in Formula1.graph_grad_softmax/1\n    (nx 0.1.0-dev) lib/nx/defn/evaluator.ex:20: Nx.Defn.Evaluator.__jit__/4\n    (stdlib 3.14) erl_eval.erl:680: :erl_eval.do_apply/6\n    (stdlib 3.14) erl_eval.erl:232: :erl_eval.expr/5\n    (stdlib 3.14) erl_eval.erl:888: :erl_eval.expr_list/6\n    (stdlib 3.14) erl_eval.erl:411: :erl_eval.expr/5\n    (elixir 1.11.3) src/elixir.erl:280: :elixir.recur_eval/3\n    (elixir 1.11.3) src/elixir.erl:265: :elixir.eval_forms/3\n    (elixir 1.11.3) lib/code.ex:700: Code.eval_quoted/3\n</pre>\n"}],"id":"07397911-2e63-4ab2-b314-6ef2e92492db","content":["import Formula\r\n1 |> Nx.tensor |> Formula.graph_grad_softmax"],"cell_type":"code"},{"running":false,"prompt_number":27,"outputs":[{"type":"code","text":["{:module, Mod, <<70, 79, 82, 49, 0, 0, 13, 228, 66, 69, 65, 77, 65, 116, 85, 56, 0, 0, 1, 244, 0, 0, 0, 41, 10, 69, 108, 105, 120, 105, 114, 46, 77, 111, 100, 8, 95, 95, 105, 110, 102, 111, 95, 95, 10, 97, 116, ...>>, {:portion, 1}}"]}],"id":"2486e6b3-e9e8-4489-99b7-f07828d38269","content":["defmodule Mod do \r\nimport Nx.Defn\r\ndefn softmax(t), do: Nx.exp(t) / Nx.sum(Nx.exp(t))\r\ndefn portion(t), do: t / Nx.sum(t)\r\nend"],"cell_type":"code"},{"running":false,"prompt_number":28,"outputs":[{"type":"code","text":["#Nx.Tensor<\n  s64[4]\n  [1, 2, 3, 4]\n>"]}],"id":"336f18d8-af27-4ce3-aa4b-a7cd22912bb2","content":["tt = Nx.tensor([1,2,3,4])"],"cell_type":"code"},{"running":false,"prompt_number":29,"outputs":[{"type":"code","text":["#Nx.Tensor<\n  f32[4]\n  [0.032058604061603546, 0.08714432269334793, 0.23688282072544098, 0.6439142227172852]\n>"]}],"id":"4ab7309f-ffae-453c-ab0d-d8844ed5ad14","content":["Mod.softmax tt"],"cell_type":"code"},{"running":false,"prompt_number":30,"outputs":[{"type":"code","text":["#Nx.Tensor<\n  f32[4]\n  [0.10000000149011612, 0.20000000298023224, 0.30000001192092896, 0.4000000059604645]\n>"]}],"id":"f847aa99-4167-4af1-92ce-dc0900f1e491","content":["Mod.portion tt"],"cell_type":"code"}]}],"metadata":{"name":"Kicking the tyres on Nx - Numerical Elixir - Robert Ellen - Elixir Australia"}}